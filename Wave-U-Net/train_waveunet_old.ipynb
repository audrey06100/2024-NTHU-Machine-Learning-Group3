{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FoNQtbKb6fib","executionInfo":{"status":"ok","timestamp":1732960861735,"user_tz":-480,"elapsed":67504,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"13b986e1-6d2e-40e7-af30-c6a07c2dc876"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Wave-U-Net"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-YrfdpI6lsy","executionInfo":{"status":"ok","timestamp":1732960861736,"user_tz":-480,"elapsed":17,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"93061247-045f-4339-e048-0cc40fd78034"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Wave-U-Net\n"]}]},{"cell_type":"code","source":["!pip install tensorflow-gpu\n","!pip install tqdm pystoi pesq\n","!pip install json5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"uNNOl4x36wF5","executionInfo":{"status":"ok","timestamp":1732863868014,"user_tz":-480,"elapsed":14840,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"73a35226-bc24-4b2a-b7f6-12fcb4897091"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-gpu\n","  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Collecting pystoi\n","  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n","Collecting pesq\n","  Downloading pesq-0.0.4.tar.gz (38 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pystoi) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pystoi) (1.13.1)\n","Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n","Building wheels for collected packages: pesq\n","  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pesq: filename=pesq-0.0.4-cp310-cp310-linux_x86_64.whl size=262948 sha256=9733574a4863b64dc34ead9b01458e3667e40dae12b554b6764969d8ecc71af6\n","  Stored in directory: /root/.cache/pip/wheels/c5/4e/2c/251524370c0fdd659e99639a0fbd0ca5a782c3aafcd456b28d\n","Successfully built pesq\n","Installing collected packages: pesq, pystoi\n","Successfully installed pesq-0.0.4 pystoi-0.4.1\n","Collecting json5\n","  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n","Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n","Installing collected packages: json5\n","Successfully installed json5-0.10.0\n"]}]},{"cell_type":"markdown","source":["## Create Dataset .txt Files"],"metadata":{"id":"85YfRhTlGVsQ"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n"],"metadata":{"id":"XTwLVV_5qYzE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["noisy_speech_duration = pd.read_csv('/content/drive/MyDrive/audio/noisy_speech_duration.csv')\n","noisy_speech_duration.head()"],"metadata":{"id":"AliLmBJGqbeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filtered_duration = noisy_speech_duration[noisy_speech_duration['duration(s)']>1]\n","filtered_duration = filtered_duration[filtered_duration['duration(s)']<=3]\n","len(noisy_speech_duration), len(filtered_duration)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9S3kkZE_GzY","executionInfo":{"status":"ok","timestamp":1732817973516,"user_tz":-480,"elapsed":300,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"31f6673f-9b33-4ac7-9f23-522840500377"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(43591, 21135)"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["noisy_speech = filtered_duration['filename'].to_list()\n","clean_speech = 'common_voice_zh-TW_' + filtered_duration['filename'].str[:8] + '_filtered.mp3'\n","clean_speech = clean_speech.to_list()"],"metadata":{"id":"H8DaAWzUzlOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"fQbF2sUv2K-B"}},{"cell_type":"code","source":["path1 = '/content/drive/MyDrive/audio/noisy_train/'\n","path2 = '/content/drive/MyDrive/audio/clean_train/'\n","files1 = os.listdir(path1)\n","files2 = os.listdir(path2)\n","\n","filtered_files1 = [f for f in files1 if f in noisy_speech]\n","filtered_files2 = [f for f in files2 if f in clean_speech]\n","\n","print(len(files1), len(files2))\n","print(len(filtered_files1), len(filtered_files2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBw-C_XGy8ya","executionInfo":{"status":"ok","timestamp":1732818051904,"user_tz":-480,"elapsed":46374,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"4976f56b-f82d-4766-87f9-6743e6bc9f35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["34537 34537\n","16876 16876\n"]}]},{"cell_type":"code","source":["filtered_files1.sort()\n","filtered_files2.sort()\n","print(filtered_files1[:5])\n","print(filtered_files2[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXyoqois1BEO","executionInfo":{"status":"ok","timestamp":1732818051905,"user_tz":-480,"elapsed":24,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"1d85ecfe-b1c0-4954-bed1-7b1083e99a7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['17367897_5-210612-A-37.mp3', '17367903_5-204114-A-29.mp3', '17367905_4-218199-F-35.mp3', '17367906_5-157204-A-16.mp3', '17367907_1-32373-A-35.mp3']\n","['common_voice_zh-TW_17367897_filtered.mp3', 'common_voice_zh-TW_17367903_filtered.mp3', 'common_voice_zh-TW_17367905_filtered.mp3', 'common_voice_zh-TW_17367906_filtered.mp3', 'common_voice_zh-TW_17367907_filtered.mp3']\n"]}]},{"cell_type":"code","source":["[f[:8] for f in filtered_files1] == [f.replace('common_voice_zh-TW_','').replace('_filtered.mp3','') for f in filtered_files2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7zvhz4np1iI3","executionInfo":{"status":"ok","timestamp":1732818051906,"user_tz":-480,"elapsed":21,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"ad7b1dd7-2328-4209-af22-ebdf259048bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["path_write = '/content/drive/MyDrive/Wave-U-Net/Datasets/MCV_ESC/trainset.txt'\n","with open(path_write, 'w+') as txt:\n","  for i in range(len(filtered_files1)):\n","    string = path1 + filtered_files1[i] + ' ' + path2 + filtered_files2[i]\n","    #print('string', string)\n","    txt.write(string + '\\n')"],"metadata":{"id":"ajQkxtH92TTf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Validation"],"metadata":{"id":"w0lgn81_2OHK"}},{"cell_type":"code","source":["path1 = '/content/drive/MyDrive/audio/noisy_valid/'\n","path2 = '/content/drive/MyDrive/audio/clean_valid/'\n","files1 = os.listdir(path1)\n","files2 = os.listdir(path2)\n","\n","filtered_files1 = [f for f in files1 if f in noisy_speech]\n","filtered_files2 = [f for f in files2 if f in clean_speech]\n","\n","print(len(files1), len(files2))\n","print(len(filtered_files1), len(filtered_files2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pHcJkvU2J6j","executionInfo":{"status":"ok","timestamp":1732818066024,"user_tz":-480,"elapsed":14131,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"ecfd63d3-5288-4fd1-ac0f-5a8eb76a5f30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8463 8463\n","4021 4021\n"]}]},{"cell_type":"code","source":["filtered_files1.sort()\n","filtered_files2.sort()\n","print(filtered_files1[:5])\n","print(filtered_files2[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"seHI_F1a3HzS","executionInfo":{"status":"ok","timestamp":1732818066025,"user_tz":-480,"elapsed":39,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"532dee17-38cf-4bb7-ac11-b5f46d370165"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['17367899_3-130998-B-28.mp3', '17367900_3-120526-B-37.mp3', '17367904_3-93010-A-18.mp3', '17368625_3-145387-A-29.mp3', '17368627_3-159347-B-36.mp3']\n","['common_voice_zh-TW_17367899_filtered.mp3', 'common_voice_zh-TW_17367900_filtered.mp3', 'common_voice_zh-TW_17367904_filtered.mp3', 'common_voice_zh-TW_17368625_filtered.mp3', 'common_voice_zh-TW_17368627_filtered.mp3']\n"]}]},{"cell_type":"code","source":["[f[:8] for f in filtered_files1] == [f.replace('common_voice_zh-TW_','').replace('_filtered.mp3','') for f in filtered_files2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Pz5lafy3PRl","executionInfo":{"status":"ok","timestamp":1732818066026,"user_tz":-480,"elapsed":33,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"cda222d9-347f-4f7c-e81e-6f7e9f2d0b2d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["path_write = '/content/drive/MyDrive/Wave-U-Net/Datasets/MCV_ESC/validset.txt'\n","with open(path_write, 'w+') as txt:\n","  for i in range(len(filtered_files1)):\n","    string = path1 + filtered_files1[i] + ' ' + path2 + filtered_files2[i]\n","    #print('string', string)\n","    txt.write(string + '\\n')"],"metadata":{"id":"WCprUwZn3Szv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train model"],"metadata":{"id":"JYI3fqfURHxY"}},{"cell_type":"code","source":["!python train.py -C config/train/1129_train_01.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8gJRpmsNMfYi","executionInfo":{"status":"ok","timestamp":1732869999930,"user_tz":-480,"elapsed":5206722,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"8119e099-2776-4136-df0a-b005e092d9f4","collapsed":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","2024-11-29 07:19:56.936234: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-29 07:19:56.953851: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-29 07:19:56.975081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-29 07:19:56.981487: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-29 07:19:56.996826: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-29 07:19:58.170635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Configurations are as follows: \n","{\n","  seed: 0,\n","  description: \"...des\",\n","  root_dir: \"./Experiments/1129_train_01\",\n","  cudnn_deterministic: false,\n","  trainer: {\n","    module: \"trainer.trainer\",\n","    main: \"Trainer\",\n","    epochs: 50,\n","    save_checkpoint_interval: 5,\n","    validation: {\n","      interval: 10,\n","      find_max: true,\n","      custom: {\n","        visualize_audio_limit: 20,\n","        visualize_waveform_limit: 20,\n","        visualize_spectrogram_limit: 20,\n","        sample_length: 16384,\n","      },\n","    },\n","  },\n","  model: {\n","    module: \"model.unet_basic\",\n","    main: \"Model\",\n","    args: {},\n","  },\n","  loss_function: {\n","    module: \"model.loss\",\n","    main: \"mse_loss\",\n","    args: {},\n","  },\n","  optimizer: {\n","    lr: 0.001,\n","    beta1: 0.9,\n","    beta2: 0.999,\n","  },\n","  train_dataset: {\n","    module: \"dataset.waveform_dataset\",\n","    main: \"Dataset\",\n","    args: {\n","      dataset: \"./Datasets/MCV_ESC/trainset.txt\",\n","      limit: null,\n","      offset: 0,\n","      sample_length: 16384,\n","      mode: \"train\",\n","    },\n","  },\n","  validation_dataset: {\n","    module: \"dataset.waveform_dataset\",\n","    main: \"Dataset\",\n","    args: {\n","      dataset: \"./Datasets/MCV_ESC/validset.txt\",\n","      limit: 400,\n","      offset: 0,\n","      mode: \"validation\",\n","    },\n","  },\n","  train_dataloader: {\n","    batch_size: 32,\n","    num_workers: 40,\n","    shuffle: true,\n","    pin_memory: true,\n","  },\n","  experiment_name: \"1129_train_01\",\n","  config_path: \"config/train/1129_train_01.json\",\n","}\n","This project contains 1 networks, the number of the parameters: \n","\tNetwork 1: 10.132802 million.\n","The amount of parameters is 10.132802 million.\n","============== 1 epoch ==============\n","[0 seconds] Begin training...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","[308 seconds] End this epoch.\n","============== 2 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 3 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 4 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 5 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 5 epoch model checkpoint...\n","[84 seconds] End this epoch.\n","============== 6 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 7 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 8 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 9 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 10 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 10 epoch model checkpoint...\n","[84 seconds] Training is over. Validation is in progress...\n","\t Saving 10 epoch model checkpoint...\n","\t Found best score in 10 epoch, saving...\n","[645 seconds] End this epoch.\n","============== 11 epoch ==============\n","[0 seconds] Begin training...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","[76 seconds] End this epoch.\n","============== 12 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 13 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 14 epoch ==============\n","[0 seconds] Begin training...\n","[74 seconds] End this epoch.\n","============== 15 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 15 epoch model checkpoint...\n","[76 seconds] End this epoch.\n","============== 16 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 17 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 18 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 19 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 20 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 20 epoch model checkpoint...\n","[76 seconds] Training is over. Validation is in progress...\n","\t Saving 20 epoch model checkpoint...\n","\t Found best score in 20 epoch, saving...\n","[210 seconds] End this epoch.\n","============== 21 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 22 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 23 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 24 epoch ==============\n","[0 seconds] Begin training...\n","[74 seconds] End this epoch.\n","============== 25 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 25 epoch model checkpoint...\n","[77 seconds] End this epoch.\n","============== 26 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 27 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 28 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 29 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 30 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 30 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","\t Saving 30 epoch model checkpoint...\n","\t Found best score in 30 epoch, saving...\n","[211 seconds] End this epoch.\n","============== 31 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 32 epoch ==============\n","[0 seconds] Begin training...\n","[74 seconds] End this epoch.\n","============== 33 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 34 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 35 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 35 epoch model checkpoint...\n","[76 seconds] End this epoch.\n","============== 36 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 37 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 38 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 39 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 40 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 40 epoch model checkpoint...\n","[76 seconds] Training is over. Validation is in progress...\n","\t Saving 40 epoch model checkpoint...\n","\t Found best score in 40 epoch, saving...\n","[210 seconds] End this epoch.\n","============== 41 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 42 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 43 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 44 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 45 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 45 epoch model checkpoint...\n","[76 seconds] End this epoch.\n","============== 46 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 47 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 48 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 49 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 50 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 50 epoch model checkpoint...\n","[76 seconds] Training is over. Validation is in progress...\n","\t Saving 50 epoch model checkpoint...\n","\t Found best score in 50 epoch, saving...\n","[209 seconds] End this epoch.\n"]}]},{"cell_type":"code","source":["!python train.py -C config/train/1129_train_01.json -R"],"metadata":{"id":"tioiqZJ3i8WL","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1732876137641,"user_tz":-480,"elapsed":1252382,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"fed79329-6fec-4609-9a35-41373cc34b15"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","2024-11-29 09:12:57.623902: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-29 09:12:57.641571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-29 09:12:57.662721: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-29 09:12:57.669212: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-29 09:12:57.684496: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-29 09:12:58.866449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/Wave-U-Net/trainer/base_trainer.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(latest_model_path.as_posix(), map_location=self.device)\n","Model checkpoint loaded. Training will begin in 51 epoch.\n","Configurations are as follows: \n","{\n","  seed: 0,\n","  description: \"...des\",\n","  root_dir: \"./Experiments/1129_train_01\",\n","  cudnn_deterministic: false,\n","  trainer: {\n","    module: \"trainer.trainer\",\n","    main: \"Trainer\",\n","    epochs: 100,\n","    save_checkpoint_interval: 10,\n","    validation: {\n","      interval: 10,\n","      find_max: true,\n","      custom: {\n","        visualize_audio_limit: 20,\n","        visualize_waveform_limit: 20,\n","        visualize_spectrogram_limit: 20,\n","        sample_length: 16384,\n","      },\n","    },\n","  },\n","  model: {\n","    module: \"model.unet_basic\",\n","    main: \"Model\",\n","    args: {},\n","  },\n","  loss_function: {\n","    module: \"model.loss\",\n","    main: \"mse_loss\",\n","    args: {},\n","  },\n","  optimizer: {\n","    lr: 0.001,\n","    beta1: 0.9,\n","    beta2: 0.999,\n","  },\n","  train_dataset: {\n","    module: \"dataset.waveform_dataset\",\n","    main: \"Dataset\",\n","    args: {\n","      dataset: \"./Datasets/MCV_ESC/trainset.txt\",\n","      limit: null,\n","      offset: 0,\n","      sample_length: 16384,\n","      mode: \"train\",\n","    },\n","  },\n","  validation_dataset: {\n","    module: \"dataset.waveform_dataset\",\n","    main: \"Dataset\",\n","    args: {\n","      dataset: \"./Datasets/MCV_ESC/validset.txt\",\n","      limit: 400,\n","      offset: 0,\n","      mode: \"validation\",\n","    },\n","  },\n","  train_dataloader: {\n","    batch_size: 32,\n","    num_workers: 40,\n","    shuffle: true,\n","    pin_memory: true,\n","  },\n","  experiment_name: \"1129_train_01\",\n","  config_path: \"config/train/1129_train_01.json\",\n","}\n","This project contains 1 networks, the number of the parameters: \n","\tNetwork 1: 10.132802 million.\n","The amount of parameters is 10.132802 million.\n","============== 51 epoch ==============\n","[0 seconds] Begin training...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","[84 seconds] End this epoch.\n","============== 52 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 53 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 54 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 55 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 56 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 57 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 58 epoch ==============\n","[0 seconds] Begin training...\n","[82 seconds] End this epoch.\n","============== 59 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 60 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 60 epoch model checkpoint...\n","[85 seconds] Training is over. Validation is in progress...\n","\t Saving 60 epoch model checkpoint...\n","\t Found best score in 60 epoch, saving...\n","[222 seconds] End this epoch.\n","============== 61 epoch ==============\n","[0 seconds] Begin training...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","[76 seconds] End this epoch.\n","============== 62 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 63 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 64 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 65 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 66 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 67 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 68 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 69 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 70 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 70 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","\t Saving 70 epoch model checkpoint...\n","\t Found best score in 70 epoch, saving...\n","[210 seconds] End this epoch.\n","============== 71 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 72 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 73 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 74 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 75 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 76 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 77 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 78 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 79 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 80 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 80 epoch model checkpoint...\n","[76 seconds] Training is over. Validation is in progress...\n","\t Saving 80 epoch model checkpoint...\n","\t Found best score in 80 epoch, saving...\n","[211 seconds] End this epoch.\n","============== 81 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 82 epoch ==============\n","[0 seconds] Begin training...\n","[74 seconds] End this epoch.\n","============== 83 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 84 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 85 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 86 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 87 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 88 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 89 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 90 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 90 epoch model checkpoint...\n","[76 seconds] Training is over. Validation is in progress...\n","[209 seconds] End this epoch.\n","============== 91 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 92 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 93 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 94 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 95 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 96 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 97 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 98 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 99 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 100 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 100 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","\t Saving 100 epoch model checkpoint...\n","\t Found best score in 100 epoch, saving...\n","[211 seconds] End this epoch.\n"]}]},{"cell_type":"code","source":["!python train.py -C config/train/1129_train_01.json -R"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_I_NYdteWdu","executionInfo":{"status":"ok","timestamp":1732885312062,"user_tz":-480,"elapsed":9043322,"user":{"displayName":"Yi-Ming Yun","userId":"00132257716001938536"}},"outputId":"a5a1e7f0-d3a9-4e1b-ccab-a347ca96d683"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","2024-11-29 10:31:12.442211: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-29 10:31:12.459682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-29 10:31:12.481189: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-29 10:31:12.487662: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-29 10:31:12.503064: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-29 10:31:13.674666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/Wave-U-Net/trainer/base_trainer.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(latest_model_path.as_posix(), map_location=self.device)\n","Model checkpoint loaded. Training will begin in 101 epoch.\n","Configurations are as follows: \n","{\n","  seed: 0,\n","  description: \"...des\",\n","  root_dir: \"./Experiments/1129_train_01\",\n","  cudnn_deterministic: false,\n","  trainer: {\n","    module: \"trainer.trainer\",\n","    main: \"Trainer\",\n","    epochs: 200,\n","    save_checkpoint_interval: 10,\n","    validation: {\n","      interval: 10,\n","      find_max: true,\n","      custom: {\n","        visualize_audio_limit: 20,\n","        visualize_waveform_limit: 20,\n","        visualize_spectrogram_limit: 20,\n","        sample_length: 16384,\n","      },\n","    },\n","  },\n","  model: {\n","    module: \"model.unet_basic\",\n","    main: \"Model\",\n","    args: {},\n","  },\n","  loss_function: {\n","    module: \"model.loss\",\n","    main: \"mse_loss\",\n","    args: {},\n","  },\n","  optimizer: {\n","    lr: 0.001,\n","    beta1: 0.9,\n","    beta2: 0.999,\n","  },\n","  train_dataset: {\n","    module: \"dataset.waveform_dataset\",\n","    main: \"Dataset\",\n","    args: {\n","      dataset: \"./Datasets/MCV_ESC/trainset.txt\",\n","      limit: null,\n","      offset: 0,\n","      sample_length: 16384,\n","      mode: \"train\",\n","    },\n","  },\n","  validation_dataset: {\n","    module: \"dataset.waveform_dataset\",\n","    main: \"Dataset\",\n","    args: {\n","      dataset: \"./Datasets/MCV_ESC/validset.txt\",\n","      limit: 400,\n","      offset: 0,\n","      mode: \"validation\",\n","    },\n","  },\n","  train_dataloader: {\n","    batch_size: 32,\n","    num_workers: 40,\n","    shuffle: true,\n","    pin_memory: true,\n","  },\n","  experiment_name: \"1129_train_01\",\n","  config_path: \"config/train/1129_train_01.json\",\n","}\n","This project contains 1 networks, the number of the parameters: \n","\tNetwork 1: 10.132802 million.\n","The amount of parameters is 10.132802 million.\n","============== 101 epoch ==============\n","[0 seconds] Begin training...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","[84 seconds] End this epoch.\n","============== 102 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 103 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 104 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 105 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 106 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 107 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 108 epoch ==============\n","[0 seconds] Begin training...\n","[84 seconds] End this epoch.\n","============== 109 epoch ==============\n","[0 seconds] Begin training...\n","[83 seconds] End this epoch.\n","============== 110 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 110 epoch model checkpoint...\n","[85 seconds] Training is over. Validation is in progress...\n","[220 seconds] End this epoch.\n","============== 111 epoch ==============\n","[0 seconds] Begin training...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","[75 seconds] End this epoch.\n","============== 112 epoch ==============\n","[0 seconds] Begin training...\n","[74 seconds] End this epoch.\n","============== 113 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 114 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 115 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 116 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 117 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 118 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 119 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 120 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 120 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","[208 seconds] End this epoch.\n","============== 121 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 122 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 123 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 124 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 125 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 126 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 127 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 128 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 129 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 130 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 130 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","\t Saving 130 epoch model checkpoint...\n","\t Found best score in 130 epoch, saving...\n","[211 seconds] End this epoch.\n","============== 131 epoch ==============\n","[0 seconds] Begin training...\n","[77 seconds] End this epoch.\n","============== 132 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 133 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 134 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 135 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 136 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 137 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 138 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 139 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 140 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 140 epoch model checkpoint...\n","[76 seconds] Training is over. Validation is in progress...\n","\t Saving 140 epoch model checkpoint...\n","\t Found best score in 140 epoch, saving...\n","[211 seconds] End this epoch.\n","============== 141 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 142 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 143 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 144 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 145 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 146 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 147 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 148 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 149 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 150 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 150 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","[210 seconds] End this epoch.\n","============== 151 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 152 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 153 epoch ==============\n","[0 seconds] Begin training...\n","[77 seconds] End this epoch.\n","============== 154 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 155 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 156 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 157 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 158 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 159 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 160 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 160 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","\t Saving 160 epoch model checkpoint...\n","\t Found best score in 160 epoch, saving...\n","[210 seconds] End this epoch.\n","============== 161 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 162 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 163 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 164 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 165 epoch ==============\n","[0 seconds] Begin training...\n","[77 seconds] End this epoch.\n","============== 166 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 167 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 168 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 169 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 170 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 170 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","\t Saving 170 epoch model checkpoint...\n","\t Found best score in 170 epoch, saving...\n","[210 seconds] End this epoch.\n","============== 171 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 172 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 173 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 174 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 175 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 176 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 177 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 178 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 179 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 180 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 180 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","\t Saving 180 epoch model checkpoint...\n","\t Found best score in 180 epoch, saving...\n","[210 seconds] End this epoch.\n","============== 181 epoch ==============\n","[0 seconds] Begin training...\n","[77 seconds] End this epoch.\n","============== 182 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 183 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 184 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 185 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 186 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 187 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 188 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 189 epoch ==============\n","[0 seconds] Begin training...\n","[77 seconds] End this epoch.\n","============== 190 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 190 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","[210 seconds] End this epoch.\n","============== 191 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 192 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 193 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 194 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 195 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 196 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 197 epoch ==============\n","[0 seconds] Begin training...\n","[76 seconds] End this epoch.\n","============== 198 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 199 epoch ==============\n","[0 seconds] Begin training...\n","[75 seconds] End this epoch.\n","============== 200 epoch ==============\n","[0 seconds] Begin training...\n","\t Saving 200 epoch model checkpoint...\n","[77 seconds] Training is over. Validation is in progress...\n","[209 seconds] End this epoch.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OYbRlbR_eXH7"},"execution_count":null,"outputs":[]}]}