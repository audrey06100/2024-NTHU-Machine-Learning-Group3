{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to access the files (if they are stored there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Dropout,\n",
    "    BatchNormalization, Cropping2D, ZeroPadding2D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "preprocessed_data_folder = '/content/drive/MyDrive/Unet_practice/preprocessed_data1024'\n",
    "clean_preprocessed_folder = os.path.join(preprocessed_data_folder, 'clean')\n",
    "noisy_preprocessed_folder = os.path.join(preprocessed_data_folder, 'noisy')\n",
    "\n",
    "X_train_max = 10.0\n",
    "Y_train_max = 10.0\n",
    "\n",
    "\n",
    "n_fft = 1024\n",
    "hop_length = 256\n",
    "win_length = 1024\n",
    "max_duration = 4  # 秒\n",
    "sr = 16000\n",
    "max_length = sr * max_duration  # 64000\n",
    "\n",
    "fixed_height = n_fft // 2 + 1  # 1024//2 +1 = 513\n",
    "fixed_width = (max_length - win_length) // hop_length + 1  # (64000 - 1024)//256 +1 = 247\n",
    "\n",
    "print(f\"Fixed Height (Frequency Dimension): {fixed_height}\")  #  513\n",
    "print(f\"Fixed Width (Time Steps): {fixed_width}\")  # 247\n",
    "\n",
    "\n",
    "\n",
    "def compute_log_stft(audio_path, sr=16000, n_fft=1024, hop_length=256, win_length=1024, max_duration=4):\n",
    "    \"\"\"\n",
    "    Computes the log-magnitude STFT of an audio file.\n",
    "\n",
    "    Parameters:\n",
    "        audio_path (str): Path to the audio file.\n",
    "        sr (int): Sampling rate for loading the audio.\n",
    "        n_fft (int): Number of FFT components.\n",
    "        hop_length (int): Hop length for STFT.\n",
    "        win_length (int): Window length for STFT.\n",
    "        max_duration (int): Maximum duration of the audio in seconds.\n",
    "\n",
    "    Returns:\n",
    "        log_magnitude (numpy.ndarray): Log-magnitude of the STFT.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(audio_path, sr=sr, mono=True)\n",
    "\n",
    "    # Ensure the audio length is exactly max_duration seconds (truncate or pad with zeros)\n",
    "    max_length = sr * max_duration\n",
    "    if len(audio) > max_length:\n",
    "        audio = audio[:max_length]  # Truncate to max_duration\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, max_length - len(audio)), mode='constant')  # Pad with zeros\n",
    "\n",
    "    # Compute STFT\n",
    "    stft_result = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "    # Extract magnitude and compute log-magnitude\n",
    "    magnitude = np.abs(stft_result)\n",
    "    log_magnitude = np.log1p(magnitude)\n",
    "\n",
    "    return log_magnitude\n",
    "\n",
    "\n",
    "clean_audio_folder = '/content/drive/MyDrive/Unet_practice/audio/clean_train'   \n",
    "noisy_audio_folder = '/content/drive/MyDrive/Unet_practice/audio/noisy_train'   \n",
    "\n",
    "\n",
    "os.makedirs(clean_preprocessed_folder, exist_ok=True)\n",
    "os.makedirs(noisy_preprocessed_folder, exist_ok=True)\n",
    "\n",
    "clean_audio_files = sorted([f for f in os.listdir(clean_audio_folder) if f.endswith('.mp3')])\n",
    "noisy_audio_files = sorted([f for f in os.listdir(noisy_audio_folder) if f.endswith('.mp3')])\n",
    "\n",
    "print(f\"Clean audio files: {len(clean_audio_files)}\")\n",
    "print(f\"Noisy audio files: {len(noisy_audio_files)}\")\n",
    "\n",
    "\n",
    "\n",
    "for idx, (clean_file) in enumerate(clean_audio_files):\n",
    "    clean_audio_path = os.path.join(clean_audio_folder, clean_file)\n",
    "\n",
    "    #clean path \n",
    "    clean_npy_filename = f\"{os.path.splitext(clean_file)[0]}.npy\"\n",
    "    clean_npy_path = os.path.join(clean_preprocessed_folder, clean_npy_filename)\n",
    "\n",
    "    # 檢查clean files\n",
    "    if os.path.exists(clean_npy_path):\n",
    "        print(f\"Clean file {idx+1}/{len(clean_audio_files)} 已經有了，跳過處理。\")\n",
    "        continue \n",
    "\n",
    "    try:\n",
    "        # STFT\n",
    "        clean_log_magnitude = compute_log_stft(clean_audio_path, sr=sr, n_fft=n_fft, hop_length=hop_length, win_length=win_length, max_duration=max_duration)\n",
    "\n",
    "        # 檢查shape\n",
    "        if clean_log_magnitude.shape != (fixed_height, fixed_width):\n",
    "            print(f\"调整 clean_log_magnitude 的shape {clean_log_magnitude.shape} 到 ({fixed_height}, {fixed_width})\")\n",
    "            clean_log_magnitude = librosa.util.fix_length(clean_log_magnitude, size=fixed_width, axis=1)\n",
    "\n",
    "        # save  .npy \n",
    "        np.save(clean_npy_path, clean_log_magnitude)\n",
    "\n",
    "        print(f\"Clean file {idx+1}/{len(clean_audio_files)} 處理完且已經保存了\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"處理 {clean_file} 時出錯：{e}\")\n",
    "\n",
    "print(\"所有clean files 轉乘STFT了\")\n",
    "\n",
    "# same to noisy files\n",
    "for idx, (noisy_file) in enumerate(noisy_audio_files):\n",
    "    noisy_audio_path = os.path.join(noisy_audio_folder, noisy_file)\n",
    "\n",
    "    noisy_npy_filename = f\"{os.path.splitext(noisy_file)[0]}.npy\"\n",
    "    noisy_npy_path = os.path.join(noisy_preprocessed_folder, noisy_npy_filename)\n",
    "\n",
    "    if os.path.exists(noisy_npy_path):\n",
    "        print(f\"Noisy file {idx+1}/{len(noisy_audio_files)} 已經有了，跳過處理。\")\n",
    "        continue  \n",
    "    try:\n",
    "        noisy_log_magnitude = compute_log_stft(noisy_audio_path, sr=sr, n_fft=n_fft, hop_length=hop_length, win_length=win_length, max_duration=max_duration)\n",
    "\n",
    "        if noisy_log_magnitude.shape != (fixed_height, fixed_width):\n",
    "            print(f\"调整 noisy_log_magnitude 的形状从 {noisy_log_magnitude.shape} 到 ({fixed_height}, {fixed_width})\")\n",
    "            noisy_log_magnitude = librosa.util.fix_length(noisy_log_magnitude, size=fixed_width, axis=1)\n",
    "\n",
    "        np.save(noisy_npy_path, noisy_log_magnitude)\n",
    "\n",
    "        print(f\"Noisy file {idx+1}/{len(noisy_audio_files)}  處理完且已經保存了\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"處理 {noisy_file} 時出錯：{e}\")\n",
    "\n",
    "print(\"所有noisy files 轉乘STFT了\")\n",
    "\n",
    "\n",
    "clean_npy_files = sorted([f for f in os.listdir(clean_preprocessed_folder) if f.endswith('.npy')])\n",
    "noisy_npy_files = sorted([f for f in os.listdir(noisy_preprocessed_folder) if f.endswith('.npy')])\n",
    "\n",
    "print(f\"Clean preprocessed files: {len(clean_npy_files)}\")\n",
    "print(f\"Noisy preprocessed files: {len(noisy_npy_files)}\")\n",
    "\n",
    "\n",
    "clean_mapping = {}\n",
    "for f in clean_npy_files:\n",
    "# 提取數字\n",
    "    base_name = os.path.splitext(f)[0]  \n",
    "    parts = base_name.split('_')\n",
    "    identifier = ''\n",
    "    for part in parts:\n",
    "        if part.isdigit():\n",
    "            identifier = part\n",
    "            break\n",
    "        elif any(char.isdigit() for char in part):\n",
    "            identifier = ''.join(filter(str.isdigit, part))\n",
    "            break\n",
    "    if identifier:\n",
    "        clean_mapping[identifier] = os.path.join(clean_preprocessed_folder, f)\n",
    "    else:\n",
    "        print(f\"沒法提取{f}\")\n",
    "\n",
    "print(f\"clean files num: {len(clean_mapping)}\")\n",
    "\n",
    "# match clean and noisy \n",
    "paired_noisy_paths = []\n",
    "paired_clean_paths = []\n",
    "\n",
    "missing_clean_files = []\n",
    "\n",
    "for f in noisy_npy_files:\n",
    "\n",
    "    base_name = os.path.splitext(f)[0]\n",
    "    identifier = ''\n",
    "    parts = base_name.split('_')\n",
    "    if parts:\n",
    "        identifier = ''.join(filter(str.isdigit, parts[0]))\n",
    "    else:\n",
    "        print(f\"沒法提取 {f}\")\n",
    "        continue\n",
    "\n",
    "    if identifier in clean_mapping:\n",
    "        paired_noisy_paths.append(os.path.join(noisy_preprocessed_folder, f))\n",
    "        paired_clean_paths.append(clean_mapping[identifier])\n",
    "    else:\n",
    "        missing_clean_files.append(f)\n",
    "\n",
    "#  check missing \n",
    "if missing_clean_files:\n",
    "    print(\"these files didnt match \")\n",
    "    for f in missing_clean_files:\n",
    "        print(f)\n",
    "else:\n",
    "    print(\"ALL MATCHED!\")\n",
    "\n",
    "print(f\"有效match num: {len(paired_noisy_paths)}\")\n",
    "\n",
    "# check the number of clean and noisy if they are same?\n",
    "assert len(paired_noisy_paths) == len(paired_clean_paths), \"clean 的數量和noisy 不一樣多\"\n",
    "\n",
    "# check\n",
    "print(\" first five files for checking out!\")\n",
    "for i in range(min(5, len(paired_noisy_paths))):\n",
    "    noisy_file = os.path.basename(paired_noisy_paths[i])\n",
    "    clean_file = os.path.basename(paired_clean_paths[i])\n",
    "    print(f\"noisy: {noisy_file} <--> clean: {clean_file}\")\n",
    "\n",
    "def load_npy(noisy_path, clean_path):\n",
    "    try:\n",
    "        \n",
    "        noisy_path = noisy_path.numpy().decode('utf-8')\n",
    "        clean_path = clean_path.numpy().decode('utf-8')\n",
    "\n",
    "       \n",
    "        noisy = np.load(noisy_path)\n",
    "        clean = np.load(clean_path)\n",
    "\n",
    "        # check shape \n",
    "        if noisy.shape != (fixed_height, fixed_width):\n",
    "            print(f\"adjust noisy's shape from  {noisy.shape} to ({fixed_height}, {fixed_width})\")\n",
    "            noisy = librosa.util.fix_length(noisy, size=fixed_width, axis=1)\n",
    "        if clean.shape != (fixed_height, fixed_width):\n",
    "            print(f\"adjust clean's shape from {clean.shape} to ({fixed_height}, {fixed_width})\")\n",
    "            clean = librosa.util.fix_length(clean, size=fixed_width, axis=1)\n",
    "\n",
    "        # add channel\n",
    "        noisy = noisy.astype(np.float32)[..., np.newaxis]  # (513, 247, 1)\n",
    "        clean = clean.astype(np.float32)[..., np.newaxis]  # (513, 247, 1)\n",
    "\n",
    "        # regular\n",
    "        noisy /= X_train_max\n",
    "        clean /= Y_train_max\n",
    "\n",
    "        return noisy, clean\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"load error: {noisy_path} 或 {clean_path} -> {e}\")\n",
    "        #return all zeros\n",
    "        noisy = np.zeros((fixed_height, fixed_width, 1), dtype=np.float32)\n",
    "        clean = np.zeros((fixed_height, fixed_width, 1), dtype=np.float32)\n",
    "        return noisy, clean\n",
    "\n",
    "# load\n",
    "def tf_load_npy(noisy_path, clean_path):\n",
    "    noisy, clean = tf.py_function(\n",
    "        func=load_npy,\n",
    "        inp=[noisy_path, clean_path],\n",
    "        Tout=[tf.float32, tf.float32]\n",
    "    )\n",
    "    # set shape \n",
    "    noisy.set_shape([fixed_height, fixed_width, 1])\n",
    "    clean.set_shape([fixed_height, fixed_width, 1])\n",
    "    return noisy, clean\n",
    "\n",
    "#\n",
    "dataset = tf.data.Dataset.from_tensor_slices((paired_noisy_paths, paired_clean_paths))\n",
    "dataset = dataset.map(tf_load_npy, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=1000)\n",
    "dataset = dataset.batch(64) \n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "split = int(0.9 * len(paired_noisy_paths))\n",
    "train_dataset = dataset.take(split)\n",
    "val_dataset = dataset.skip(split)\n",
    "\n",
    "print(f\"train num: {split}\")\n",
    "print(f\"valid num: {len(paired_noisy_paths) - split}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, BatchNormalization, Dropout, MaxPooling2D,\n",
    "    Conv2DTranspose, ZeroPadding2D, Cropping2D, concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# ==========================\n",
    "# 辅助函数\n",
    "# ==========================\n",
    "def adjust_shape(tensor_a, tensor_b):\n",
    "    \"\"\"\n",
    "    Adjusts tensor_b to match the shape of tensor_a by cropping or padding.\n",
    "    \"\"\"\n",
    "    shape_a = tensor_a.shape\n",
    "    shape_b = tensor_b.shape\n",
    "\n",
    "    height_diff = shape_a[1] - shape_b[1]\n",
    "    width_diff = shape_a[2] - shape_b[2]\n",
    "\n",
    "    if None in [shape_a[1], shape_a[2], shape_b[1], shape_b[2]]:\n",
    "        raise ValueError(\"One of the tensor dimensions is undefined. Please provide input_shape with fixed dimensions.\")\n",
    "\n",
    "    if height_diff > 0:\n",
    "        tensor_b = ZeroPadding2D(padding=((0, height_diff), (0, 0)))(tensor_b)\n",
    "    elif height_diff < 0:\n",
    "        tensor_b = Cropping2D(cropping=((0, -height_diff), (0, 0)))(tensor_b)\n",
    "\n",
    "    if width_diff > 0:\n",
    "        tensor_b = ZeroPadding2D(padding=((0, 0), (0, width_diff)))(tensor_b)\n",
    "    elif width_diff < 0:\n",
    "        tensor_b = Cropping2D(cropping=((0, 0), (0, -width_diff)))(tensor_b)\n",
    "\n",
    "    return tensor_b\n",
    "\n",
    "def unet(input_shape=(513, 247, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.1)(conv1)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.1)(conv2)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Dropout(0.3)(conv5)\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "    up6 = adjust_shape(conv4, up6)\n",
    "    merge6 = concatenate([conv4, up6], axis=-1)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.2)(conv6)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = adjust_shape(conv3, up7)\n",
    "    merge7 = concatenate([conv3, up7], axis=-1)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = adjust_shape(conv2, up8)\n",
    "    merge8 = concatenate([conv2, up8], axis=-1)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Dropout(0.1)(conv8)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = adjust_shape(conv1, up9)\n",
    "    merge9 = concatenate([conv1, up9], axis=-1)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Dropout(0.1)(conv9)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    return mse + 0.5 * mae\n",
    "\n",
    "\n",
    "for noisy_batch, clean_batch in train_dataset.take(1):\n",
    "    print(f\"Noisy batch shape: {noisy_batch.shape}\")\n",
    "    print(f\"Clean batch shape: {clean_batch.shape}\")\n",
    "\n",
    "for noisy_val_batch, clean_val_batch in val_dataset.take(1):\n",
    "    print(f\"Noisy validation batch shape: {noisy_val_batch.shape}\")\n",
    "    print(f\"Clean validation batch shape: {clean_val_batch.shape}\")\n",
    "\n",
    "\n",
    "input_shape = (513, 247, 1)\n",
    "model = unet(input_shape=input_shape)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=combined_loss, metrics=['mae'])\n",
    "\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/Unet_practice/logs\"\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "checkpoint_callback = ModelCheckpoint(filepath='/content/drive/MyDrive/Unet_practice/20epochtest_model.keras',\n",
    "                                      save_weights_only=False, save_best_only=True,\n",
    "                                      monitor='val_loss', mode='min', verbose=1)\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=1,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint_callback, tensorboard_callback]\n",
    ")\n",
    "\n",
    "print(\"complete!!!!!!!!!!yeahhhhhhhhh!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('/content/drive/MyDrive/Unet_practice/final_model.h5')\n",
    "print(\"already save the model to  /content/drive/MyDrive/Unet_practice/final_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
